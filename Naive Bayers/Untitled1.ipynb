{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0bd8eb-3794-43eb-a682-897bdbb2678c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    100\u001b[39m data_frames.append(df_4)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Classe 5: Tentativa de Acesso Não Autorizado (não é transação, mas um evento de fraude)\u001b[39;00m\n\u001b[32m    103\u001b[39m df_5 = pd.DataFrame({\n\u001b[32m    104\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mQuantia_Transacao\u001b[39m\u001b[33m'\u001b[39m: np.random.normal(\u001b[32m0\u001b[39m, \u001b[32m0.1\u001b[39m, num_samples_per_class[\u001b[32m5\u001b[39m]).clip(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m), \u001b[38;5;66;03m# Quantia irrelevante (evento)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFreq_Transacoes_ID\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples_per_class\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;66;03m# Não é transação\u001b[39;00m\n\u001b[32m    106\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRisco_Localizacao\u001b[39m\u001b[33m'\u001b[39m: np.random.uniform(\u001b[32m0.8\u001b[39m, \u001b[32m1.0\u001b[39m, num_samples_per_class[\u001b[32m5\u001b[39m]), \u001b[38;5;66;03m# Muito alto risco (IPs suspeitos)\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHorario_Risco\u001b[39m\u001b[33m'\u001b[39m: np.random.uniform(\u001b[32m0.8\u001b[39m, \u001b[32m1.0\u001b[39m, num_samples_per_class[\u001b[32m5\u001b[39m]), \u001b[38;5;66;03m# Madrugadas/picos de ataque\u001b[39;00m\n\u001b[32m    108\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTentativas_Login_Falhas\u001b[39m\u001b[33m'\u001b[39m: np.random.randint(\u001b[32m3\u001b[39m, \u001b[32m10\u001b[39m, num_samples_per_class[\u001b[32m5\u001b[39m]), \u001b[38;5;66;03m# Múltiplas falhas\u001b[39;00m\n\u001b[32m    109\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mNum_Itens\u001b[39m\u001b[33m'\u001b[39m: np.random.randint(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, num_samples_per_class[\u001b[32m5\u001b[39m]), \u001b[38;5;66;03m# Não aplica\u001b[39;00m\n\u001b[32m    110\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTipo_Fraude\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m5\u001b[39m\n\u001b[32m    111\u001b[39m })\n\u001b[32m    112\u001b[39m data_frames.append(df_5)\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Concatenando todos os DataFrames\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\mtrand.pyx:794\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.randint\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\_bounded_integers.pyx:1425\u001b[39m, in \u001b[36mnumpy.random._bounded_integers._rand_int32\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: high <= 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. Preparação dos Dados ---\n",
    "# Criando um dataset sintético para identificação de fraude com 6 classes.\n",
    "# Cada classe representará um tipo de transação (legítima ou fraudulenta).\n",
    "# As características (features) serão numéricas e podem representar:\n",
    "# - Quantia da Transação (ex: valor em R$)\n",
    "# - Frequência de Transações por ID (ex: quantas transações em um curto período)\n",
    "# - Localização Geográfica (ex: proximidade de áreas de risco, ou diferença de país)\n",
    "# - Horário da Transação (ex: madrugadas)\n",
    "# - Tentativas de Login Falhas (para um tipo de fraude online)\n",
    "# - Número de Itens na Transação\n",
    "\n",
    "# Definindo as 6 classes de transação:\n",
    "# 0: Transação Legítima (maioria)\n",
    "# 1: Fraude de Cartão Clonado (transações grandes, fora do padrão)\n",
    "# 2: Fraude de Identidade (muitas transações pequenas, novo padrão)\n",
    "# 3: Fraude de Reembolso (transações grandes, devoluções rápidas)\n",
    "# 4: Fraude de Compras Online (pequenas, repetidas, ou de alto risco)\n",
    "# 5: Tentativa de Acesso Não Autorizado (não é transação, mas um evento de fraude)\n",
    "\n",
    "np.random.seed(42) # Para reprodutibilidade\n",
    "\n",
    "num_samples_per_class = {\n",
    "    0: 1000,  # Legítima (maioria)\n",
    "    1: 50,   # Cartão Clonado\n",
    "    2: 70,   # Identidade\n",
    "    3: 30,   # Reembolso\n",
    "    4: 80,   # Compras Online\n",
    "    5: 40    # Acesso Não Autorizado\n",
    "}\n",
    "\n",
    "# Criando DataFrames para cada classe com características específicas\n",
    "data_frames = []\n",
    "\n",
    "# Classe 0: Transação Legítima\n",
    "df_0 = pd.DataFrame({\n",
    "    'Quantia_Transacao': np.random.normal(50, 20, num_samples_per_class[0]).clip(min=1),\n",
    "    'Freq_Transacoes_ID': np.random.randint(1, 5, num_samples_per_class[0]),\n",
    "    'Risco_Localizacao': np.random.uniform(0.1, 0.4, num_samples_per_class[0]),\n",
    "    'Horario_Risco': np.random.uniform(0.1, 0.3, num_samples_per_class[0]), # Ex: 0-1, onde 1 é alto risco (madrugada)\n",
    "    'Tentativas_Login_Falhas': np.random.randint(0, 1, num_samples_per_class[0]),\n",
    "    'Num_Itens': np.random.randint(1, 5, num_samples_per_class[0]),\n",
    "    'Tipo_Fraude': 0\n",
    "})\n",
    "data_frames.append(df_0)\n",
    "\n",
    "# Classe 1: Fraude de Cartão Clonado\n",
    "df_1 = pd.DataFrame({\n",
    "    'Quantia_Transacao': np.random.normal(300, 50, num_samples_per_class[1]).clip(min=100), # Quantias maiores\n",
    "    'Freq_Transacoes_ID': np.random.randint(1, 3, num_samples_per_class[1]), # Poucas transações, mas suspeitas\n",
    "    'Risco_Localizacao': np.random.uniform(0.6, 0.9, num_samples_per_class[1]), # Alta de risco\n",
    "    'Horario_Risco': np.random.uniform(0.6, 0.9, num_samples_per_class[1]), # Madrugada/horas incomuns\n",
    "    'Tentativas_Login_Falhas': np.random.randint(0, 1, num_samples_per_class[1]),\n",
    "    'Num_Itens': np.random.randint(1, 3, num_samples_per_class[1]),\n",
    "    'Tipo_Fraude': 1\n",
    "})\n",
    "data_frames.append(df_1)\n",
    "\n",
    "# Classe 2: Fraude de Identidade (muitas pequenas, novo padrão)\n",
    "df_2 = pd.DataFrame({\n",
    "    'Quantia_Transacao': np.random.normal(20, 10, num_samples_per_class[2]).clip(min=1), # Quantias menores\n",
    "    'Freq_Transacoes_ID': np.random.randint(5, 15, num_samples_per_class[2]), # Alta frequência\n",
    "    'Risco_Localizacao': np.random.uniform(0.5, 0.8, num_samples_per_class[2]),\n",
    "    'Horario_Risco': np.random.uniform(0.4, 0.7, num_samples_per_class[2]),\n",
    "    'Tentativas_Login_Falhas': np.random.randint(0, 1, num_samples_per_class[2]),\n",
    "    'Num_Itens': np.random.randint(1, 3, num_samples_per_class[2]),\n",
    "    'Tipo_Fraude': 2\n",
    "})\n",
    "data_frames.append(df_2)\n",
    "\n",
    "# Classe 3: Fraude de Reembolso (transações grandes, devoluções rápidas)\n",
    "df_3 = pd.DataFrame({\n",
    "    'Quantia_Transacao': np.random.normal(500, 100, num_samples_per_class[3]).clip(min=200), # Quantias muito grandes\n",
    "    'Freq_Transacoes_ID': np.random.randint(1, 2, num_samples_per_class[3]), # Poucas, mas isoladas e grandes\n",
    "    'Risco_Localizacao': np.random.uniform(0.7, 0.95, num_samples_per_class[3]), # Alta de risco\n",
    "    'Horario_Risco': np.random.uniform(0.5, 0.8, num_samples_per_class[3]),\n",
    "    'Tentativas_Login_Falhas': np.random.randint(0, 1, num_samples_per_class[3]),\n",
    "    'Num_Itens': np.random.randint(1, 2, num_samples_per_class[3]), # Geralmente poucos itens, mas caros\n",
    "    'Tipo_Fraude': 3\n",
    "})\n",
    "data_frames.append(df_3)\n",
    "\n",
    "# Classe 4: Fraude de Compras Online (pequenas, repetidas, ou de alto risco)\n",
    "df_4 = pd.DataFrame({\n",
    "    'Quantia_Transacao': np.random.normal(80, 30, num_samples_per_class[4]).clip(min=1),\n",
    "    'Freq_Transacoes_ID': np.random.randint(3, 7, num_samples_per_class[4]),\n",
    "    'Risco_Localizacao': np.random.uniform(0.4, 0.7, num_samples_per_class[4]), # Risco intermediário/alto\n",
    "    'Horario_Risco': np.random.uniform(0.3, 0.6, num_samples_per_class[4]),\n",
    "    'Tentativas_Login_Falhas': np.random.randint(0, 1, num_samples_per_class[4]),\n",
    "    'Num_Itens': np.random.randint(2, 6, num_samples_per_class[4]),\n",
    "    'Tipo_Fraude': 4\n",
    "})\n",
    "data_frames.append(df_4)\n",
    "\n",
    "# Classe 5: Tentativa de Acesso Não Autorizado (não é transação, mas um evento de fraude)\n",
    "df_5 = pd.DataFrame({\n",
    "    'Quantia_Transacao': np.random.normal(0, 0.1, num_samples_per_class[5]).clip(min=0), # Quantia irrelevante (evento)\n",
    "    'Freq_Transacoes_ID': np.random.randint(0, 0, num_samples_per_class[5]), # Não é transação\n",
    "    'Risco_Localizacao': np.random.uniform(0.8, 1.0, num_samples_per_class[5]), # Muito alto risco (IPs suspeitos)\n",
    "    'Horario_Risco': np.random.uniform(0.8, 1.0, num_samples_per_class[5]), # Madrugadas/picos de ataque\n",
    "    'Tentativas_Login_Falhas': np.random.randint(3, 10, num_samples_per_class[5]), # Múltiplas falhas\n",
    "    'Num_Itens': np.random.randint(0, 0, num_samples_per_class[5]), # Não aplica\n",
    "    'Tipo_Fraude': 5\n",
    "})\n",
    "data_frames.append(df_5)\n",
    "\n",
    "\n",
    "# Concatenando todos os DataFrames\n",
    "df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Embaralhar o DataFrame para garantir que as classes não estejam em ordem sequencial\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Exemplo do Dataset (primeiras 5 linhas):\\n\", df.head())\n",
    "print(f\"\\nNúmero total de amostras: {len(df)}\")\n",
    "print(\"Distribuição das classes (Tipos de Fraude):\\n\", df['Tipo_Fraude'].value_counts().sort_index())\n",
    "\n",
    "# Separando características (X) e rótulos (y)\n",
    "X = df.drop('Tipo_Fraude', axis=1).values\n",
    "y = df['Tipo_Fraude'].values\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste.\n",
    "# test_size=0.3 significa 30% para teste, 70% para treino.\n",
    "# random_state=42 para reprodutibilidade da divisão.\n",
    "# stratify=y é CRUCIAL para garantir que a proporção das 6 classes seja mantida\n",
    "# nos conjuntos de treino e teste, especialmente porque as classes estão desbalanceadas.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"\\n--- Dados Após Divisão ---\")\n",
    "print(f\"Shape de X_train (treino): {X_train.shape}\")\n",
    "print(f\"Shape de X_test (teste): {X_test.shape}\")\n",
    "print(f\"Shape de y_train (rótulos de treino): {y_train.shape}\")\n",
    "print(f\"Shape de y_test (rótulos de teste): {y_test.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Treinamento do Modelo (Fase de Aprendizado)\n",
    "# Usaremos o Gaussian Naive Bayes, pois as características são numéricas e contínuas.\n",
    "\n",
    "# Inicializando o classificador Gaussian Naive Bayes.\n",
    "# O parâmetro 'var_smoothing' é usado para adicionar um pequeno valor à variância\n",
    "# de cada característica para evitar variâncias de zero. Isso previne problemas\n",
    "# de cálculo de probabilidade e torna o modelo mais robusto.\n",
    "gnb = GaussianNB(var_smoothing=1e-9)\n",
    "\n",
    "# Treinando o modelo com os dados de treinamento (X_train e y_train).\n",
    "# O algoritmo calcula as médias e variâncias de cada característica\n",
    "# para CADA UMA das 6 classes de fraude/transação.\n",
    "# Também calcula as probabilidades a priori de cada classe.\n",
    "print(\"\\n--- Treinando o Modelo Gaussian Naive Bayes ---\")\n",
    "gnb.fit(X_train, y_train)\n",
    "print(\"Modelo treinado com sucesso!\")\n",
    "\n",
    "\n",
    "# 3. Classificação de Novos Dados (Fase de Predição)\n",
    "# Agora, usamos o modelo treinado para prever os tipos de fraude/transação no conjunto de teste.\n",
    "\n",
    "print(\"\\n--- Realizando Previsões ---\")\n",
    "# Fazendo previsões de classe para os dados de teste.\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Obtendo as probabilidades de cada amostra pertencer a cada uma das 6 classes.\n",
    "# As colunas correspondem às classes em ordem crescente (0, 1, 2, 3, 4, 5).\n",
    "y_proba = gnb.predict_proba(X_test)\n",
    "\n",
    "print(f\"Primeiras 10 previsões de tipo de fraude: {y_pred[:10]}\")\n",
    "print(f\"Probabilidades das primeiras 2 previsões (arredondadas):\\n {y_proba[:2].round(3)}\")\n",
    "\n",
    "# Exemplo de previsão para uma nova transação (hipotética)\n",
    "# Uma transação de alto valor, com risco de localização alto, mas sem tentativas de login.\n",
    "nova_transacao = np.array([[450, 1, 0.9, 0.7, 0, 2]])\n",
    "pred_nova = gnb.predict(nova_transacao)\n",
    "proba_nova = gnb.predict_proba(nova_transacao)\n",
    "\n",
    "# Mapeamento para nomes de classe mais legíveis\n",
    "class_names_map = {\n",
    "    0: 'Legítima',\n",
    "    1: 'Cartão Clonado',\n",
    "    2: 'Identidade',\n",
    "    3: 'Reembolso',\n",
    "    4: 'Compras Online',\n",
    "    5: 'Acesso Não Autorizado'\n",
    "}\n",
    "\n",
    "print(f\"\\nPrevisão para nova transação: {class_names_map[pred_nova[0]]} (Classe {pred_nova[0]})\")\n",
    "print(\"Probabilidades para a nova transação:\")\n",
    "for i, prob in enumerate(proba_nova[0]):\n",
    "    print(f\"  {class_names_map[i]}: {prob:.4f}\")\n",
    "\n",
    "\n",
    "# 4. Avaliação do Modelo\n",
    "# Avaliando o desempenho do nosso classificador de fraude multiclasse.\n",
    "\n",
    "print(\"\\n--- Avaliação do Modelo ---\")\n",
    "\n",
    "# Acurácia: Proporção de previsões corretas sobre o total.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do Modelo: {accuracy:.4f}\")\n",
    "\n",
    "# Relatório de Classificação: Fornece precisão, recall e F1-score para cada uma das 6 classes.\n",
    "# target_names mapeia os rótulos numéricos para nomes mais descritivos.\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\n",
    "    'Legítima', 'Cartão Clonado', 'Identidade', 'Reembolso', 'Compras Online', 'Acesso Não Autorizado'\n",
    "]))\n",
    "\n",
    "# Matriz de Confusão: Essencial para problemas multiclasse e desbalanceados.\n",
    "# Mostra o número de acertos e erros para cada par de classes.\n",
    "# Linhas: Classes Reais (True Labels)\n",
    "# Colunas: Classes Previstas (Predicted Labels)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualizando a Matriz de Confusão (muito útil para múltiplas classes)\n",
    "plt.figure(figsize=(9, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\n",
    "                'Previsto Legítima', 'Previsto Clonado', 'Previsto Identidade',\n",
    "                'Previsto Reembolso', 'Previsto Online', 'Previsto Acesso'\n",
    "            ],\n",
    "            yticklabels=[\n",
    "                'Real Legítima', 'Real Clonado', 'Real Identidade',\n",
    "                'Real Reembolso', 'Real Online', 'Real Acesso'\n",
    "            ])\n",
    "plt.xlabel('Rótulo Previsto')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.title('Matriz de Confusão para Identificação de Fraude (Gaussian Naive Bayes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416d48f-1fb4-42a6-86f0-1049cbc6d179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
